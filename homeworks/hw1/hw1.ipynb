{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLx6P9fT/ye0rAX2wX0B98"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BHffEq3fRAjy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "-B7d1TmaRXCe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9640d25a-7817-4dbb-ccdf-164cb4ca7a78"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для загрузки данных\n",
        "def load_data(train_csv, val_csv, test_csv):\n",
        "    train_data = pd.read_csv(train_csv)\n",
        "    val_data = pd.read_csv(val_csv)\n",
        "    test_data = pd.read_csv(test_csv)\n",
        "\n",
        "    # Используем только 360 признаков (координаты и скорости)\n",
        "    X_train = train_data.iloc[:, :-3].values\n",
        "    y_train = train_data['order0'].values\n",
        "\n",
        "    X_val = val_data.iloc[:, :-3].values\n",
        "    y_val = val_data['order0'].values\n",
        "\n",
        "    X_test = test_data.values  # в тесте нет order0, только 360 признаков\n",
        "\n",
        "    # Нормализация данных\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_val = scaler.transform(X_val)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test"
      ],
      "metadata": {
        "id": "vF5TQX2yRHV9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определим многослойный персептрон\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout для регуляризации\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)  # Dropout на скрытом слое\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ZiiV-rftb1Yp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация модели, критерия и оптимизатора\n",
        "def init_model(input_size=360, hidden_size=256, output_size=3, lr=0.001):\n",
        "    model = MLP(input_size, hidden_size, output_size)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    return model, criterion, optimizer"
      ],
      "metadata": {
        "id": "xedxbJNURJZD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для оценки модели\n",
        "def evaluate(model, X, y=None):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(torch.tensor(X, dtype=torch.float32))\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        if y is not None:\n",
        "            accuracy = accuracy_score(y, predictions.numpy())\n",
        "            conf_matrix = confusion_matrix(y, predictions.numpy())\n",
        "            return predictions, accuracy, conf_matrix\n",
        "        else:\n",
        "            return predictions, None, None"
      ],
      "metadata": {
        "id": "tY2ZOaHZRLRX"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция обучения модели\n",
        "def train(model, criterion, optimizer, X_train, y_train, X_val, y_val, epochs=10, batch_size=64):\n",
        "    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Оценка на валидационной выборке\n",
        "        _, val_accuracy, _ = evaluate(model, X_val, y_val)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cvSeTJJHRNfi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_csv = '/content/gdrive/MyDrive/ColabNotebooks/2024/train.txt'\n",
        "    val_csv = '/content/gdrive/MyDrive/ColabNotebooks/2024/val.txt'\n",
        "    test_csv = '/content/gdrive/MyDrive/ColabNotebooks/2024/test.txt'\n",
        "    out_csv = '/content/gdrive/MyDrive/ColabNotebooks/2024/submission.csv'\n",
        "    lr = 0.001\n",
        "    batch_size = 64\n",
        "    num_epoches = 10\n",
        "\n",
        "    # Загрузка данных\n",
        "    X_train, y_train, X_val, y_val, X_test = load_data(train_csv, val_csv, test_csv)\n",
        "\n",
        "    # Инициализация модели\n",
        "    model, criterion, optimizer = init_model(lr=lr)\n",
        "\n",
        "    # Обучение модели\n",
        "    trained_model = train(model, criterion, optimizer, X_train, y_train, X_val, y_val, epochs=num_epoches, batch_size=batch_size)\n",
        "\n",
        "    # Предсказания на тестовом наборе\n",
        "    predictions, _, _ = evaluate(trained_model, X_test, None)\n",
        "\n",
        "    # Сохранение предсказаний в файл submission.csv\n",
        "    pd.DataFrame(predictions.numpy(), columns=['order0']).to_csv(out_csv, index=False)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "GkKWN0HNRQdF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d1f320-66e5-499a-b943-c35dfd01a8ab"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.8292, Val Accuracy: 0.7116\n",
            "Epoch 2/10, Loss: 0.7751, Val Accuracy: 0.7356\n",
            "Epoch 3/10, Loss: 0.7623, Val Accuracy: 0.7478\n",
            "Epoch 4/10, Loss: 0.7549, Val Accuracy: 0.7311\n",
            "Epoch 5/10, Loss: 0.7523, Val Accuracy: 0.7525\n",
            "Epoch 6/10, Loss: 0.7485, Val Accuracy: 0.7418\n",
            "Epoch 7/10, Loss: 0.7455, Val Accuracy: 0.7613\n",
            "Epoch 8/10, Loss: 0.7427, Val Accuracy: 0.7511\n",
            "Epoch 9/10, Loss: 0.7405, Val Accuracy: 0.7429\n",
            "Epoch 10/10, Loss: 0.7395, Val Accuracy: 0.7488\n"
          ]
        }
      ]
    }
  ]
}
