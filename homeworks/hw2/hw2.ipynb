{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgHLMvUkIsHLkf6S3jJxQ4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tjXKw7fnNO5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74315108-2c16-41d6-fd93-1181b91ba7ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "rEZAS0IN0uun"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Encoded pixels to masks and vice versa functions\n",
        "def encoded_pixels_to_masks(fname: str, df: pd.DataFrame):\n",
        "    fname_df = df[df['ImageId'] == fname]\n",
        "    masks = np.zeros((256 * 1600, 4), dtype=int)\n",
        "\n",
        "    for i_row, row in fname_df.iterrows():\n",
        "        cls_id = row['ClassId']\n",
        "        encoded_pixels = row['EncodedPixels']\n",
        "        if encoded_pixels is not np.nan:\n",
        "            pixel_list = list(map(int, encoded_pixels.split(' ')))\n",
        "            for i in range(0, len(pixel_list), 2):\n",
        "                start_pixel = pixel_list[i] - 1\n",
        "                num_pixel = pixel_list[i+1]\n",
        "                masks[start_pixel:(start_pixel+num_pixel), cls_id-1] = 1\n",
        "\n",
        "    masks = masks.reshape(256, 1600, 4, order='F')\n",
        "    return masks"
      ],
      "metadata": {
        "id": "fS0KrLXa0utA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Dataset class\n",
        "class SeverstalSteelDataset(Dataset):\n",
        "    def __init__(self, fnames, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.fnames = fnames\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fnames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.fnames[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_id)\n",
        "        img = np.array(Image.open(img_path).convert('RGB'))  # Загружаем изображение\n",
        "        masks = encoded_pixels_to_masks(img_id, self.df)  # Генерируем маску\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "        img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)  # Преобразуем в тензор\n",
        "        masks = torch.tensor(masks, dtype=torch.float32).permute(2, 0, 1)  # Преобразуем в тензор\n",
        "        return img_id, img, masks"
      ],
      "metadata": {
        "id": "TiYy-Asy0url"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Optional collate function\n",
        "def collate_fn(batch_items):\n",
        "    batched_fnames = [item[0] for item in batch_items]\n",
        "    batched_imgs = torch.stack([item[1] for item in batch_items])\n",
        "    batched_masks = torch.stack([item[2] for item in batch_items])\n",
        "    return batched_fnames, batched_imgs, batched_masks"
      ],
      "metadata": {
        "id": "e9e-EgrM0uo4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Model class\n",
        "!pip install segmentation-models-pytorch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "class SegModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegModel, self).__init__()\n",
        "        self.model = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', classes=4, activation=None)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEASquyW0umJ",
        "outputId": "98202bbe-9f72-4733-c3f6-18bd84db027b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.24.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (10.4.0)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n",
            "Collecting timm==0.9.7 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.19.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.4.1+cu121)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.26.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n",
            "Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16425 sha256=017d8566d21e456d109e4cbbb9b2411f91684a0d0d28228b397b5f32b6367862\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=d10b06c96a872c2e0d0c536b40f72104553996c451078947c7df5797722922f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Data loading function\n",
        "def load_data(train_val_csv, test_csv, train_val_img_dir, test_img_dir):\n",
        "    train_val_df = pd.read_csv(train_val_csv)\n",
        "    train_val_fnames = pd.unique(train_val_df.ImageId)\n",
        "\n",
        "    test_df = pd.read_csv(test_csv)\n",
        "    test_fnames = pd.unique(test_df.ImageId)\n",
        "\n",
        "    # Split train and val data\n",
        "    train_fnames, val_fnames = train_test_split(train_val_fnames, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_dataset = SeverstalSteelDataset(train_fnames, train_val_df, train_val_img_dir)\n",
        "    val_dataset = SeverstalSteelDataset(val_fnames, train_val_df, train_val_img_dir)\n",
        "    test_dataset = SeverstalSteelDataset(test_fnames, test_df, test_img_dir)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "1oZM22oX0ujh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Model initialization\n",
        "def init_model():\n",
        "    model = SegModel()\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()  # Используем BCE с логитами для многоклассовой задачи\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    return model, criterion, optimizer"
      ],
      "metadata": {
        "id": "tidiVz0B0ug2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Dice Score function\n",
        "def dice_score(preds, targets, smooth=1e-6):\n",
        "    preds = preds.reshape(-1)\n",
        "    targets = targets.reshape(-1)\n",
        "\n",
        "    intersection = (preds * targets).sum()  # Считаем пересечение\n",
        "    return (2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth)  # Добавляем небольшое число для избежания деления на 0"
      ],
      "metadata": {
        "id": "riyLTqDI0ueK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Dice Score per class\n",
        "def dice_score_per_class(preds, targets, smooth=1e-6):\n",
        "    dice_per_class = []\n",
        "    for i in range(preds.shape[1]):\n",
        "        dice = dice_score(preds[:, i], targets[:, i], smooth)\n",
        "        dice_per_class.append(dice.item())\n",
        "    return dice_per_class"
      ],
      "metadata": {
        "id": "lMG3c52z0ubP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Average Dice Score\n",
        "def average_dice_score(preds, targets, smooth=1e-6):\n",
        "    dice_per_class = dice_score_per_class(preds, targets, smooth)\n",
        "    mean_dice = np.mean(dice_per_class)\n",
        "    return mean_dice, dice_per_class"
      ],
      "metadata": {
        "id": "BjgU9O300uWo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Задание индивидуальных порогов для каждого класса\n",
        "thresholds = [0.5, 0.5, 0.4, 0.5]\n",
        "\n",
        "# Модификация функции для использования индивидуальных порогов\n",
        "def masks_to_encoded_pixels(mask, class_idx, thresholds):\n",
        "    threshold = thresholds[class_idx]  # Берем порог для текущего класса\n",
        "    pixels = mask.flatten(order='F')\n",
        "    pixels = np.where(pixels > threshold, 1, 0)  # Применяем индивидуальный порог\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "metadata": {
        "id": "Q_8u1HJVmrds"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Training function\n",
        "def train(model, criterion, optimizer, loader, epochs, device):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for batch_fnames, batch_imgs, batch_masks in loader:\n",
        "            batch_imgs, batch_masks = batch_imgs.to(device), batch_masks.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_imgs)\n",
        "            loss = criterion(outputs, batch_masks)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(loader)}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ih0EcKIs0uRA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Validation function\n",
        "def validate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    dice_scores = []\n",
        "    with torch.no_grad():\n",
        "        for batch_fnames, batch_imgs, batch_masks in val_loader:\n",
        "            batch_imgs, batch_masks = batch_imgs.to(device), batch_masks.to(device)\n",
        "            outputs = model(batch_imgs)\n",
        "            preds = torch.sigmoid(outputs) > 0.5  # Применяем порог для получения масок\n",
        "            preds = preds.cpu().numpy()\n",
        "            batch_masks = batch_masks.cpu().numpy()\n",
        "\n",
        "            for i in range(len(batch_fnames)):\n",
        "                for cls_id in range(4):\n",
        "                    dice = dice_score(preds[i, cls_id], batch_masks[i, cls_id])\n",
        "                    dice_scores.append(dice)\n",
        "\n",
        "    mean_dice = np.mean(dice_scores)\n",
        "    print(f\"Average Dice Score: {mean_dice:.4f}\")\n",
        "    for cls_id in range(4):\n",
        "        cls_dice = np.mean([score for i, score in enumerate(dice_scores) if i % 4 == cls_id])\n",
        "        print(f\"Dice Score for Class {cls_id + 1}: {cls_dice:.4f}\")"
      ],
      "metadata": {
        "id": "6bmvYn15UMW8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация submission с индивидуальными порогами\n",
        "def generate_submission(model, test_loader, device, thresholds):\n",
        "    model.eval()\n",
        "    submission = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_fnames, batch_imgs, _ in test_loader:\n",
        "            batch_imgs = batch_imgs.to(device)\n",
        "            outputs = model(batch_imgs)\n",
        "            preds = torch.sigmoid(outputs)  # Применяем сигмоиду\n",
        "\n",
        "            preds = preds.cpu().numpy()\n",
        "            for i, fname in enumerate(batch_fnames):\n",
        "                encoded_pixels_list = []\n",
        "                for cls_id in range(4):  # Проходим по каждому классу\n",
        "                    encoded_pixels = masks_to_encoded_pixels(preds[i, cls_id], cls_id, thresholds)\n",
        "                    encoded_pixels_list.append((fname, cls_id + 1, encoded_pixels))\n",
        "\n",
        "                submission.extend(encoded_pixels_list)\n",
        "\n",
        "    # Создаем DataFrame для submission\n",
        "    submission_df = pd.DataFrame(submission, columns=['ImageId', 'ClassId', 'EncodedPixels'])\n",
        "    submission_df.to_csv('/content/gdrive/MyDrive/ColabNotebooks/2024/HW2/submission.csv', index=False)"
      ],
      "metadata": {
        "id": "D3wOqIqjmMFJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Main execution block\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the data\n",
        "train_loader, val_loader, test_loader = load_data(\n",
        "    '/content/gdrive/MyDrive/ColabNotebooks/2024/HW2/train.csv',\n",
        "    '/content/gdrive/MyDrive/ColabNotebooks/2024/HW2/sample_submission.csv',\n",
        "    '/content/gdrive/MyDrive/ColabNotebooks/2024/HW2/train_images/',\n",
        "    '/content/gdrive/MyDrive/ColabNotebooks/2024/HW2/test_images/'\n",
        ")\n",
        "\n",
        "# Initialize the model\n",
        "model, criterion, optimizer = init_model()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWu_oFVpnDSm",
        "outputId": "88a85890-a7ee-409b-81f7-75440007af1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 187MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SegModel(\n",
              "  (model): Unet(\n",
              "    (encoder): ResNetEncoder(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (3): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (3): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (4): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (5): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): UnetDecoder(\n",
              "      (center): Identity()\n",
              "      (blocks): ModuleList(\n",
              "        (0): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (1): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (2): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (3): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (4): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (segmentation_head): SegmentationHead(\n",
              "      (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Identity()\n",
              "      (2): Activation(\n",
              "        (activation): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train(model, criterion, optimizer, train_loader, epochs=2, device=device)"
      ],
      "metadata": {
        "id": "SYs-vmUcnF8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cfd53d-32c8-4ee6-8345-776afc36e2b5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Loss: 0.24148171116923284\n",
            "Epoch 2/2, Loss: 0.0609162078201324\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SegModel(\n",
              "  (model): Unet(\n",
              "    (encoder): ResNetEncoder(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (3): BasicBlock(\n",
              "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (3): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (4): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (5): BasicBlock(\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (2): BasicBlock(\n",
              "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): UnetDecoder(\n",
              "      (center): Identity()\n",
              "      (blocks): ModuleList(\n",
              "        (0): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (1): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (2): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (3): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "        (4): DecoderBlock(\n",
              "          (conv1): Conv2dReLU(\n",
              "            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention1): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "          (conv2): Conv2dReLU(\n",
              "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (attention2): Attention(\n",
              "            (attention): Identity()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (segmentation_head): SegmentationHead(\n",
              "      (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Identity()\n",
              "      (2): Activation(\n",
              "        (activation): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "validate(model, val_loader, device)"
      ],
      "metadata": {
        "id": "mg5inBfZnIb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af999ae4-e3c8-4e93-ca38-ea1e08902b7e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Dice Score: 0.8026\n",
            "Dice Score for Class 1: 0.7444\n",
            "Dice Score for Class 2: 0.9753\n",
            "Dice Score for Class 3: 0.5915\n",
            "Dice Score for Class 4: 0.8993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказания на тестовом наборе и генерация submission файла\n",
        "generate_submission(model, test_loader, device, thresholds)"
      ],
      "metadata": {
        "id": "jE9XxejbnJ5Y"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}
