## HW 4

### Описание
В скором времени AGI агенты достигнут уровня развития человека. А значит им придется столкнуться с проблемами, которые раньше были свойственны только людям. 
Им придется сдавать ЕГЭ. Поэтому мы решили заранее помочь им подготовиться к экзамену по литературе.
Агент прочитал романы Война и Мир Толстого и Преступление и наказание Достоевского, но мало что запомнил. Поможем ему понять эти романы лучше. 
Для этого мы научим его определять по вырванной цитате из романа, к какому роману она относится.

### Данные
train.csv - обучающая выборка, содержит 2 поля: 
* text - текст цитаты
* label - метка класса (0 - Война и Мир, 1 - Преступление и наказание)

train-test.txt - plain текст вперемешку цитат из обоих романов.

### Задача
1. **Обучить классификатор** (фактически та же задача, что и на практике 5):
* Разбить train.csv на train и valid выборки 
* Обучить модель, которая по тексту цитаты будет определять к какому роману она относится. Необходимо использовать модель "distilbert/distilroberta-base" из huggingface.
* Протестировать на valid: confusion_matrix, accuracy, f1. Сохранить эти метрики.
2. **Претренировать модель с помощью unsupervised masked language modeling** на train-test.txt
* Воспользоваться вот этим туториалом https://huggingface.co/docs/transformers/main/tasks/masked_language_modeling
* Вывести метрики perplexity и loss до и после обучения
3. **Перетренировать классификатор из пункта 1**, но использовать претренированные веса из пункта 2
* сравнить метрики с пунктом 1

### Требования к решению
* Ноутбук с кодом и метриками
* Веса обученной модели из пункта 3 сохранить trainer.save_model(path). По ним будет считаться test score.











